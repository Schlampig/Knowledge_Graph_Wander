## **Web Crawler**


### Source
  * [Common Crawl](https://commoncrawl.org/): an open repository of web crawl data that can be accessed and analyzed by anyone.

### Tools
  * [Scrapy](https://github.com/scrapy/scrapy)
  * [Pyspider](https://github.com/binux/pyspider)
  * [InfoSpider](https://github.com/kangvcar/InfoSpider)

### Literatures/Books

### Awesome-crawler
  * link: https://github.com/BruceDone/awesome-crawler
  * author: Bruce Tang
  * note: a collection of awesome web crawler,spider in different languages

### examples-of-web-crawlers
  * link: https://github.com/shengqiangzhang/examples-of-web-crawlers
  * author: Shengqiang Zhang
  * note: some interesting examples of python crawlers that are friendly to beginners.

### Crack-JS
  * link: https://github.com/xianyucoder/Crack-JS
  * blog: http://xianyucoder.cn/
  * author: huangjin
  * note: Python3çˆ¬è™«é¡¹ç›®è¿›é˜¶å®æˆ˜.
  
### wechat-spider
  * link: https://github.com/striver-ing/wechat-spider
  * author: striver-ing
  * note: å¼€æºå¾®ä¿¡çˆ¬è™«ï¼šçˆ¬å–å…¬ä¼—å·æ‰€æœ‰ æ–‡ç« ã€é˜…è¯»é‡ã€ç‚¹èµé‡å’Œè¯„è®ºå†…å®¹.

### crawlab
  * link: https://github.com/crawlab-team/crawlab
  * author: [Crawlab Team](https://github.com/crawlab-team)
  * note: åˆ†å¸ƒå¼çˆ¬è™«ç®¡ç†å¹³å°ï¼Œæ”¯æŒä»»ä½•è¯­è¨€å’Œæ¡†æ¶.

### paperscraper
  * link: https://github.com/PhosphorylatedRabbits/paperscraper
  * author: PhosphorylatedRabbits
  * note: tools to scrape publication metadata from pubmed, arxiv, medrxiv and chemrxiv.

### arxiv2latex
  * link: https://github.com/liuyixin-louis/arxiv2latex
  * author: Yixin Liu
  * note: download the source latex code of multiple arxiv paper with one click.

### magical_spider
  * link: https://github.com/lixi5338619/magical_spider
  * author: æçº
  * note: ç¥å¥‡çš„èœ˜è››ğŸ•·ï¼Œä¸€ä¸ªå‡ ä¹é€‚ç”¨äºæ‰€æœ‰webç«¯ç«™ç‚¹çš„é‡‡é›†æ–¹æ¡ˆ.

### Newspaper3k
  * link: https://github.com/codelucas/newspaper
  * author: Lucas Ou-Yang
  * note: news, full-text, and article metadata extraction in python 3.
